{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Preamble\" data-toc-modified-id=\"Preamble-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Preamble</a></span></li><li><span><a href=\"#Different-Regions\" data-toc-modified-id=\"Different-Regions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Different Regions</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Functions</a></span></li><li><span><a href=\"#Indivual-Phases\" data-toc-modified-id=\"Indivual-Phases-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Indivual Phases</a></span></li><li><span><a href=\"#Bootstrap\" data-toc-modified-id=\"Bootstrap-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Bootstrap</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-Count-Array\" data-toc-modified-id=\"Create-Count-Array-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Create Count Array</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Functions</a></span></li><li><span><a href=\"#Running-and-Saving\" data-toc-modified-id=\"Running-and-Saving-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Running and Saving</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-19.01/lib/python3.6/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-19.01/lib/python3.6/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import dask.array\n",
    "import cartopy.crs as ccrs\n",
    "import pickle\n",
    "import matplotlib.colors as colors\n",
    "import datetime as dt\n",
    "rb = plt.cm.RdBu\n",
    "bm = plt.cm.Blues\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'RMM.pickle'\n",
    "pickle_in = open(path, 'rb')\n",
    "RMM = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load /home/563/ab2313/MJO/get_awap.py\n",
    "import sys\n",
    "\n",
    "def get_platform():\n",
    "    platforms = {\n",
    "        'linux1' : 'Linux',\n",
    "        'linux2' : 'Linux',\n",
    "        'darwin' : 'OS X',\n",
    "        'win32' : 'Windows'\n",
    "    }\n",
    "\n",
    "    if sys.platform not in platforms:\n",
    "        return sys.platform\n",
    "\n",
    "    return platforms[sys.platform]\n",
    "\n",
    "\n",
    "platform = get_platform()\n",
    "\n",
    "\n",
    "if platform == 'OS X':\n",
    "    path =  '/Users/alexborowiak/Desktop/large_files/'\n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "else:\n",
    "#     path = '/home/student.unimelb.edu.au/aborowiak/Desktop/Code/Scripts/big_files/'\n",
    "    path = '/home/563/ab2313/big_files/'\n",
    "\n",
    "\n",
    "# precip = xr.open_dataset(path + 'AWAP_w.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "precip = xr.open_dataset(path + 'AWAP_W.nc', chunks={'time':-1, 'lat': 50, 'lon': 50}).precip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMM = RMM.reset_index()\n",
    "RMM['Date'] = RMM['Date'] + pd.to_timedelta('9h')\n",
    "RMM = RMM.set_index('Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rainfall is divided into different phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = np.array([slice(110, 120),slice(120.25, 140),slice(140.25, 156.25)])\n",
    "mjo_enhanced_list = np.array([[4,5],[4,5,6],[4,5,6,7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is creating 3 seperate data frames comprised of the rainfall just in the individual phases\n",
    "\n",
    "\n",
    "########## Enhanced\n",
    "\n",
    "region_data = []\n",
    "\n",
    "for reg_num in [0,1,2]:\n",
    "    region = regions[reg_num]\n",
    "    precip_region = precip.sel(lon = region)\n",
    "\n",
    "    mjo_enhanced = mjo_enhanced_list[reg_num]\n",
    "    enhanced_dates = np.array(RMM[np.logical_and(RMM['Phase'].isin(mjo_enhanced), RMM['Amplitude'] >= 1)].index)\n",
    "\n",
    "    precip_enhancecd = precip_region.where(precip_region.time.isin(enhanced_dates))\n",
    "    \n",
    "    region_data.append(precip_enhancecd)\n",
    "    \n",
    "enhanced_precip = (region_data[0].combine_first(region_data[1])).combine_first(region_data[2])\n",
    "\n",
    "\n",
    "\n",
    "########## Supppressed\n",
    "region_data = []\n",
    "\n",
    "for reg_num in [0,1,2]:\n",
    "    region = regions[reg_num]\n",
    "    precip_region = precip.sel(lon = region)\n",
    "\n",
    "    mjo_suppressed = mjo_enhanced_list[reg_num]\n",
    "    suppressed_dates = np.array(RMM[np.logical_and(~RMM['Phase'].isin(mjo_suppressed), RMM['Amplitude'] >= 1)].index)\n",
    "\n",
    "    precip_enhancecd = precip_region.where(precip_region.time.isin(suppressed_dates))\n",
    "    \n",
    "    region_data.append(precip_enhancecd)\n",
    "    \n",
    "suppressed_precip = (region_data[0].combine_first(region_data[1])).combine_first(region_data[2])\n",
    "\n",
    "########## Inactive\n",
    "region_data = []\n",
    "\n",
    "for reg_num in [0,1,2]:\n",
    "    region = regions[reg_num]\n",
    "    precip_region = precip.sel(lon = region)\n",
    "\n",
    "    mjo_inactive = mjo_enhanced_list[reg_num]\n",
    "    inactive_dates = np.array(RMM[RMM['Amplitude'] <1].index)\n",
    "\n",
    "    precip_enhancecd = precip_region.where(precip_region.time.isin(inactive_dates))\n",
    "    \n",
    "    region_data.append(precip_enhancecd)\n",
    "    \n",
    "inactive_precip = (region_data[0].combine_first(region_data[1])).combine_first(region_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The climatology for each month. The values above this are considered to be extreme. This will be what I will\n",
    "# be counting. This is the 90th percentile of all rainfall\n",
    "\n",
    "climatology_90 = precip.groupby('time.month').reduce(np.nanpercentile, q = 90, dim = 'time')\n",
    "climatology_95 = precip.groupby('time.month').reduce(np.nanpercentile, q = 95, dim = 'time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values greater than the 90th percentile from each phase of the MJO is returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# This returns just the extremes. \n",
    "\n",
    "def return_extremes(precip, threshold):\n",
    "    storage = []\n",
    "    months = [10,11,12,1,2,3]\n",
    "    for i,month in enumerate(months):\n",
    "        precip_month = precip.where(precip.time.dt.month == month, drop = True)\n",
    "        threshold_month = threshold.sel(month = month)\n",
    "        \n",
    "        precip_month_ex = precip_month.where(precip_month >= threshold_month)\n",
    "\n",
    "        storage.append(precip_month_ex)\n",
    "        \n",
    "        if i == 0:\n",
    "            extreme_xr = precip_month_ex\n",
    "        else:\n",
    "            extreme_xr = extreme_xr.combine_first(precip_month_ex)  \n",
    "    \n",
    "    return  extreme_xr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_90 = return_extremes(enhanced_precip , climatology_90)\n",
    "suppressed_90 = return_extremes(suppressed_precip , climatology_90)\n",
    "inactive_90 = return_extremes(inactive_precip , climatology_90)\n",
    "\n",
    "precip_90 = return_extremes(precip , climatology_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_95 = return_extremes(enhanced_precip , climatology_95)\n",
    "suppressed_95 = return_extremes(suppressed_precip , climatology_95)\n",
    "inactive_95 = return_extremes(inactive_precip , climatology_95)\n",
    "\n",
    "precip_95 = return_extremes(precip , climatology_95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def into_xr(data, orgininal, name = 'precip'):\n",
    "    return xr.DataArray(\n",
    "    data,\n",
    "    dims=['lat','lon'],\n",
    "    coords={'lat':orgininal.lat, 'lon': orgininal.lon},\n",
    "    name=name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sumfrac(data_sub,data_all):\n",
    "    \n",
    "    # suming all of the extreme events\n",
    "    sum_sub = data_sub.sum(dim = 'time')\n",
    "    \n",
    "    # suming all of the rain events\n",
    "    sum_all = data_all.sum(dim = 'time')\n",
    "    \n",
    "    # Finding the ratio of the events\n",
    "    frac = sum_sub/sum_all\n",
    "    \n",
    "    \n",
    "    xr = into_xr(frac, data_all, 'precip')\n",
    "    \n",
    "    return xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_all_months_and_regions(phase_precip_ex, phase_precip, precip_ex, precip):\n",
    "    \n",
    "    months = [10,11,12,1,2,3]\n",
    "    temp_dict = {}\n",
    "    \n",
    "    for month in months:\n",
    "        ###Just the data that is in this month\n",
    "        # For the MJO Phase\n",
    "        phase_prec_month = phase_precip_ex.where(phase_precip_ex.time.dt.month == month, drop = True)\n",
    "        all_prec_month = phase_precip.where(phase_precip.time.dt.month == month, drop = True)\n",
    "        # For all rainfall \n",
    "        prec_month = precip_ex.where(precip_ex.time.dt.month == month, drop = True)\n",
    "        prec_month = precip.where(precip.time.dt.month == month, drop = True)\n",
    "        \n",
    "        \n",
    "        ##### Running the function above\n",
    "        # The fracion of extremes compared to normal rainfall for MJO phase\n",
    "        frac_phase = calculate_sumfrac(phase_prec_month ,all_prec_month)  \n",
    "        # The fracion of extremes compared to normal rainfall\n",
    "        frac_all = calculate_sumfrac(prec_month , prec_month)\n",
    "        \n",
    "        # Dividing these two will give the comparison (e.g twice as much)\n",
    "        frac_month = frac_phase/ frac_all\n",
    "        \n",
    "        # Storing the results\n",
    "        temp_dict[str(month)] = frac_month\n",
    "    \n",
    "    frac_int = xr.concat([temp_dict['10'],temp_dict['11'],temp_dict['12'],temp_dict['1'],\n",
    "                            temp_dict['2'],temp_dict['3']], pd.Index(months, name = 'month'))\n",
    "    \n",
    "    return frac_int\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indivual Phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "enhanced_sum90 = sum_all_months_and_regions(enhanced_90 , enhanced_precip, precip_90, precip)\n",
    "\n",
    "suppressed_sum90 = sum_all_months_and_regions(suppressed_90, suppressed_precip, precip_90, precip)\n",
    "\n",
    "inactive_sum90 = sum_all_months_and_regions(inactive_90, inactive_precip, precip_90, precip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_90 = xr.concat([enhanced_sum90, suppressed_sum90, inactive_sum90],\n",
    "                    pd.Index(['enhanced','suppressed','inactive'], name = 'mjo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "enhanced_sum95 = sum_all_months_and_regions(enhanced_95 , enhanced_precip, precip_95, precip)\n",
    "\n",
    "suppressed_sum95 = sum_all_months_and_regions(suppressed_95, suppressed_precip, precip_95, precip)\n",
    "\n",
    "inactive_sum95 = sum_all_months_and_regions(inactive_95, inactive_precip, precip_95, precip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_95 = xr.concat([enhanced_sum95, suppressed_sum95, inactive_sum95],\n",
    "                    pd.Index(['enhanced','suppressed','inactive'], name = 'mjo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = 0\n",
    "if save:\n",
    "    prop_95.to_netcdf('prop_95.nc')\n",
    "\n",
    "    prop_90.to_netcdf('prop_90.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "* 1: Creating the count array. This counts all of the rainfall events that occur. So this will count all in the normal and the extreme arrays. This is useful as now I only have to do a sum across all of the years (months).\n",
    "* 2: Th e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'precip' (time: 7822, lat: 53, lon: 178)>\n",
       "dask.array<shape=(7822, 53, 178), dtype=float32, chunksize=(7822, 50, 50)>\n",
       "Coordinates:\n",
       "  * lon      (lon) float64 112.0 112.2 112.5 112.8 ... 155.5 155.8 156.0 156.2\n",
       "  * time     (time) datetime64[ns] 1974-10-01T09:00:00 ... 2017-12-31T09:00:00\n",
       "  * lat      (lat) float64 -23.0 -22.75 -22.5 -22.25 ... -10.5 -10.25 -10.0\n",
       "Attributes:\n",
       "    long_name:  Daily Precipitation\n",
       "    units:      mm"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhanced_precip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'precip' (time: 7822, lat: 53, lon: 178)>\n",
       "dask.array<shape=(7822, 53, 178), dtype=float32, chunksize=(7822, 50, 50)>\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 1974-10-01T09:00:00 ... 2017-12-31T09:00:00\n",
       "  * lon      (lon) float64 112.0 112.2 112.5 112.8 ... 155.5 155.8 156.0 156.2\n",
       "  * lat      (lat) float64 -23.0 -22.75 -22.5 -22.25 ... -10.5 -10.25 -10.0\n",
       "Attributes:\n",
       "    long_name:  Daily Precipitation\n",
       "    units:      mm"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhanced_90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Count Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The count array is created to speed up the bootstrapping.\n",
    "As the end results of count is the count from every mouth, \n",
    "if the count of each month is already created, then the final \n",
    "results can just be the sum of all of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def each_year_sum(data):\n",
    "    \n",
    "    storage = []\n",
    "    #Looping through all of the months\n",
    "    months = [10,11,12,1,2,3]\n",
    "    for month in months:\n",
    "        data_month = data.where(data.time.dt.month == month, drop = True)\n",
    "        sum_year = data_month.groupby('time.year').sum(dim = 'time')\n",
    "        storage.append(sum_year)\n",
    "        \n",
    "    sum_all = xr.concat(storage, pd.Index(months, name = 'month'))\n",
    "    \n",
    "    return sum_all\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'precip' (time: 7822, lat: 53, lon: 178)>\n",
       "dask.array<shape=(7822, 53, 178), dtype=float32, chunksize=(7822, 50, 50)>\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 1974-10-01T09:00:00 ... 2017-12-31T09:00:00\n",
       "  * lon      (lon) float64 112.0 112.2 112.5 112.8 ... 155.5 155.8 156.0 156.2\n",
       "  * lat      (lat) float64 -23.0 -22.75 -22.5 -22.25 ... -10.5 -10.25 -10.0\n",
       "Attributes:\n",
       "    long_name:  Daily Precipitation\n",
       "    units:      mm"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precip_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_year_sum_90 = each_year_sum(precip_90)\n",
    "precip_year_sum_95 = each_year_sum(precip_95)\n",
    "precip_year_sum = each_year_sum(precip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_90_year_sum = each_year_sum(enhanced_90)\n",
    "sup_90_year_sum = each_year_sum(suppressed_90)\n",
    "inact_90_year_sum = each_year_sum(inactive_90)\n",
    "\n",
    "mjo_year_sum_90 = xr.concat([en_90_year_sum, sup_90_year_sum,inact_90_year_sum],\n",
    "                       pd.Index(['enhanced', 'suppressed','inactive'], name = 'mjo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_95_year_sum = each_year_sum(enhanced_95)\n",
    "sup_95_year_sum = each_year_sum(suppressed_95)\n",
    "inact_95_year_sum = each_year_sum(inactive_95)\n",
    "\n",
    "mjo_year_sum_95 = xr.concat([en_95_year_sum, sup_95_year_sum,inact_95_year_sum],\n",
    "                       pd.Index(['enhanced', 'suppressed','inactive'], name = 'mjo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_year_sum = each_year_sum(enhanced_precip)\n",
    "sup_year_sum = each_year_sum(suppressed_precip)\n",
    "inact_year_sum = each_year_sum(inactive_precip)\n",
    "\n",
    "mjo_year_sum = xr.concat([en_year_sum, sup_year_sum,inact_year_sum],\n",
    "                       pd.Index(['enhanced', 'suppressed','inactive'], name = 'mjo'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_additional(data_sub,data,uniqueValues, occurCount, number):\n",
    "\n",
    "    \n",
    "    if any(occurCount >= 2 ):\n",
    "        # Find the years that are getting sampled multiple times\n",
    "            # occurCount is the frequency of each year\n",
    "            # uniqueValues is all the years that have been sampled\n",
    "        multi_sampled_years = uniqueValues[np.where(occurCount >= 2 )]\n",
    "        \n",
    "        #  Finding the data for the additional years\n",
    "        additional = data.where(data.year.isin(multi_sampled_years), drop = True)\n",
    "        # Adding n * 100 years to the data so that they don't overlap\n",
    "        additional['year'] = additional.year +  number * 100\n",
    "        \n",
    "        # Combing all the data together\n",
    "        data_sub = data_sub.combine_first(additional)\n",
    "        \n",
    "        #### Running this whole function again (recursivly) to determine which ones have been selected more than\n",
    "           # twice\n",
    "        # Reducing the occur count by 1. This will enable the samples that have been sampeld more than twice \n",
    "        # to be determing\n",
    "        occurCount = occurCount - 1\n",
    "        number += 1\n",
    "        \n",
    "        data_sub = select_additional(data,data_sub, uniqueValues, occurCount, number) \n",
    "        \n",
    "        return data_sub\n",
    "                                \n",
    "    else:\n",
    "        return data_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sum_of_sum_frac(data_sub,data_all):\n",
    "    \n",
    "    # suming all of the extreme events\n",
    "    sum_sub = data_sub.sum(dim = 'year')\n",
    "    \n",
    "    # suming all of the rain events\n",
    "    sum_all = data_all.sum(dim = 'year')\n",
    "    \n",
    "    # Finding the ratio of the events\n",
    "    frac = sum_sub/sum_all\n",
    "    \n",
    "    return frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_all_months_and_regions(phase_precip_ex, phase_precip, precip_ex, precip):\n",
    "    \n",
    "    months = [10,11,12,1,2,3]\n",
    "    temp_dict = {}\n",
    "    \n",
    "    for month in months:\n",
    "        ###Just the data that is in this month\n",
    "        # For the MJO Phase\n",
    "        phase_prec_month = phase_precip_ex.where(phase_precip_ex.time.dt.month == month, drop = True)\n",
    "        all_prec_month = phase_precip.where(phase_precip.time.dt.month == month, drop = True)\n",
    "        # For all rainfall \n",
    "        prec_month = precip_ex.where(precip_ex.time.dt.month == month, drop = True)\n",
    "        prec_month = precip.where(precip.time.dt.month == month, drop = True)\n",
    "        \n",
    "        \n",
    "        ##### Running the function above\n",
    "        # The fracion of extremes compared to normal rainfall for MJO phase\n",
    "        frac_phase = calculate_sumfrac(phase_prec_month ,all_prec_month)  \n",
    "        # The fracion of extremes compared to normal rainfall\n",
    "        frac_all = calculate_sumfrac(prec_month , prec_month)\n",
    "        \n",
    "        # Dividing these two will give the comparison (e.g twice as much)\n",
    "        frac_month = frac_phase/ frac_all\n",
    "        \n",
    "        # Storing the results\n",
    "        temp_dict[str(month)] = frac_month\n",
    "    \n",
    "    frac_int = xr.concat([temp_dict['10'],temp_dict['11'],temp_dict['12'],temp_dict['1'],\n",
    "                            temp_dict['2'],temp_dict['3']], pd.Index(months, name = 'month'))\n",
    "    \n",
    "    return frac_int\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes in the sum for a single phase of the MJO\n",
    "\n",
    "def bootstrap_each_month_sum(phase_sum_ex, phase_sum, sum_ex, sum_p, loops):\n",
    "    \n",
    "    month_storage = []\n",
    "    \n",
    "    # Loop through all of the months. Extract the data for just one month.\n",
    "    months = [10,11,12,1,2,3]\n",
    "    for month in months:\n",
    "        \n",
    "        loop_storage = []\n",
    "        \n",
    "        # The MJO Phase\n",
    "        phase_sum_month_ex = phase_sum_ex.sel(month = month)\n",
    "        phase_sum_month = phase_sum.sel(month = month)\n",
    "        \n",
    "        # All Rainfall\n",
    "        sum_month_ex = sum_ex.sel(month = month)\n",
    "        sum_month = sum_p.sel(month = month)\n",
    "        \n",
    "        # Looping through all of the different runs\n",
    "        for i in range(loops):\n",
    "            \n",
    "            ########### Selecting Random Data\n",
    "            # Selecting random years; half the ranges of the data\n",
    "            rand_years = np.random.randint(1974,2017,22)\n",
    "    \n",
    "            # Subsetting botht the data to the randomyears\n",
    "            phase_sum_ex_rand = phase_sum_month_ex.where(phase_sum_month_ex.year.isin(rand_years)) # Extremes\n",
    "            phase_sum_rand = phase_sum_month.where(phase_sum_month.year.isin(rand_years)) # Normal\n",
    "        \n",
    "            sum_ex_rand = sum_month_ex.where(sum_month_ex.year.isin(rand_years)) # Extremes\n",
    "            sum_rand = sum_month.where(sum_month.year.isin(rand_years)) # Normal\n",
    "            \n",
    "            # If there are years that have been repeated they need to be added\n",
    "            uniqueValues, occursum = np.unique(rand_years, return_counts=True)\n",
    "            \n",
    "            # (data_sub, data)\n",
    "            phase_sum_ex_rand = select_additional(phase_sum_ex_rand,phase_sum_month_ex, uniqueValues, occursum, number = 1)\n",
    "            phase_sum_rand = select_additional(phase_sum_rand, phase_sum_month,uniqueValues, occursum, number = 1)\n",
    "            \n",
    "            sum_ex_rand = select_additional(sum_ex_rand,sum_month_ex, uniqueValues, occursum, number = 1)\n",
    "            sum_rand = select_additional(sum_rand, sum_month,uniqueValues, occursum, number = 1)\n",
    "            \n",
    "            \n",
    "            ########### Actual Calculation\n",
    "            # (data_sub, data_all)\n",
    "            # For the phase: the proportion of extremes\n",
    "            frac_phase = calculate_sum_of_sum_frac(phase_sum_ex_rand, phase_sum_rand)\n",
    "            \n",
    "            # For all rainfall: the proportion of extremes\n",
    "            frac_all = calculate_sum_of_sum_frac(sum_ex_rand, sum_rand)\n",
    "            \n",
    "            boot_run = frac_phase/frac_all\n",
    "            \n",
    "            loop_storage.append(boot_run)\n",
    "            \n",
    "            ## END OF LOOP\n",
    "        \n",
    "        month_data = xr.concat(loop_storage, 'run_num')\n",
    "        month_95 = month_data.reduce(np.nanpercentile, q = 95, dim = 'run_num')\n",
    "        month_5 = month_data.reduce(np.nanpercentile, q = 5, dim = 'run_num')\n",
    "        \n",
    "        month_boot = xr.concat([month_95, month_5], pd.Index([95,5], name = 'percentile'))\n",
    "        month_storage.append(month_boot)\n",
    "        \n",
    "    total_boot = xr.concat(month_storage, pd.Index(months, name = 'month'))\n",
    "        \n",
    "    return total_boot\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loops = 1000\n",
    "\n",
    "\n",
    "\n",
    "name = 'enhanced'\n",
    "enhanced_boot = bootstrap_each_month_sum(mjo_year_sum_90.sel(mjo = name),mjo_year_sum.sel(mjo = name),\n",
    "                                           precip_year_sum_90 ,precip_year_sum,loops)\n",
    "\n",
    "name = 'suppressed'\n",
    "suppressed_boot = bootstrap_each_month_sum(mjo_year_sum_90.sel(mjo = name),mjo_year_sum.sel(mjo = name),\n",
    "                                           precip_year_sum_90 ,precip_year_sum,loops)\n",
    "\n",
    "name = 'inactive'\n",
    "inactive_boot = bootstrap_each_month_sum(mjo_year_sum_90.sel(mjo = name),mjo_year_sum.sel(mjo = name),\n",
    "                                           precip_year_sum_90 ,precip_year_sum,loops)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_boot_90 = xr.concat([enhanced_boot, suppressed_boot, inactive_boot], \n",
    "                        pd.Index(['enhanced', 'suppressed','inactive'], name = 'mjo'))\n",
    "\n",
    "prop_boot_90.to_netcdf('prop_boot_90.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "name = 'enhanced'\n",
    "enhanced_boot = bootstrap_each_month_sum(mjo_year_sum_95.sel(mjo = name),mjo_year_sum.sel(mjo = name),\n",
    "                                           precip_year_sum_95 ,precip_year_sum,loops)\n",
    "\n",
    "name = 'suppressed'\n",
    "suppressed_boot = bootstrap_each_month_sum(mjo_year_sum_95.sel(mjo = name),mjo_year_sum.sel(mjo = name),\n",
    "                                           precip_year_sum_95 ,precip_year_sum,loops)\n",
    "\n",
    "name = 'inactive'\n",
    "inactive_boot = bootstrap_each_month_sum(mjo_year_sum_95.sel(mjo = name),mjo_year_sum.sel(mjo = name),\n",
    "                                           precip_year_sum_95 ,precip_year_sum,loops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_boot_95 = xr.concat([enhanced_boot, suppressed_boot, inactive_boot], \n",
    "                        pd.Index(['enhanced', 'suppressed','inactive'], name = 'mjo'))\n",
    "\n",
    "prop_boot_95.to_netcdf('prop_boot_95.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
